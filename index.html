<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>WebXR 2D→3D POC (Video Plane)</title>
  <style>
    html, body { margin:0; height:100%; background:#000; overflow:hidden; }
    #ui {
      position:fixed; z-index:3; left:16px; top:16px; display:flex; gap:8px; align-items:center;
      font-family:system-ui, -apple-system, Segoe UI, Roboto, sans-serif; color:#ddd;
    }
    button { background:#3b3b3b; color:#fff; border:none; padding:10px 14px; border-radius:10px; cursor:pointer; }
    button:disabled { opacity:.5; cursor:not-allowed; }
    #status { opacity:.8 }
    /* keep the HTML <video> off-screen – we only use it as a texture */
    video { position:fixed; left:-9999px; top:-9999px; width:1px; height:1px; }
  </style>
</head>
<body>
  <div id="ui">
    <button id="loadBtn">Load & Play</button>
    <span id="status">idle</span>
  </div>

  <!-- Your stream: HLS (.m3u8) works in Oculus Browser; MP4 works everywhere -->
  <video id="vid" playsinline crossorigin="anonymous" muted></video>

  <!-- three.js + helpers -->
  <script type="module">
    import * as THREE from 'https://unpkg.com/three@0.160.0/build/three.module.js';
    import { VRButton } from 'https://unpkg.com/three@0.160.0/examples/jsm/webxr/VRButton.js';

    // ====== CONFIG ======
    const STREAM_URL =
      // MP4 fallback (public demo)
      'https://test-streams.mux.dev/x36xhzz/x36xhzz.m3u8';
      // If you have a direct MP4, swap it in (often starts faster in desktop browsers)
      // 'https://d2zihajmogu5jn.cloudfront.net/bipbop-adv/master.m3u8';

    // ====== ELEMENTS ======
    const video  = document.getElementById('vid');
    const loadBtn = document.getElementById('loadBtn');
    const statusEl = document.getElementById('status');

    // If it’s HLS and the browser doesn’t do native HLS, use hls.js dynamically.
    async function attachSource(url) {
      const isHls = /\.m3u8(\?|$)/i.test(url);
      const supportsNativeHls = video.canPlayType('application/vnd.apple.mpegurl') !== '';
      if (isHls && !supportsNativeHls) {
        // lazy-load hls.js
        await import('https://cdn.jsdelivr.net/npm/hls.js@latest');
        if (window.Hls && window.Hls.isSupported()) {
          const hls = new window.Hls({ maxBufferLength: 5, liveBackBufferLength: 5 });
          hls.loadSource(url);
          hls.attachMedia(video);
          return;
        }
      }
      // Native path (or MP4)
      video.src = url;
    }

    // ====== THREE / WEBXR SCENE ======
    let renderer, scene, camera, videoTex, plane, clock;

    initThree();
    setupPlane();
    setupXRButton();
    tick();

    function initThree() {
      renderer = new THREE.WebGLRenderer({ antialias:true, alpha:false });
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
      renderer.xr.enabled = true;
      document.body.appendChild(renderer.domElement);

      scene = new THREE.Scene();
      scene.background = new THREE.Color(0x000000);

      camera = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.01, 100);
      camera.position.set(0, 1.6, 0); // eye height-ish

      clock = new THREE.Clock();

      // tiny ambient so "darkness" never happens
      const amb = new THREE.AmbientLight(0xffffff, 0.6);
      scene.add(amb);

      window.addEventListener('resize', () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    }

    function setupPlane() {
      // Start with a neutral 16:9 plane, adjust after metadata loads.
      const geom = new THREE.PlaneGeometry(2.8, 1.575); // ~2.8m wide @ 16:9
      const mat  = new THREE.MeshBasicMaterial({ color: 0xffffff });

      plane = new THREE.Mesh(geom, mat);
      plane.position.set(0, 1.6, -2); // 2 meters in front of user’s eyes
      scene.add(plane);

      // Prepare video texture but attach only after playback starts
      videoTex = new THREE.VideoTexture(video);
      videoTex.encoding = THREE.sRGBEncoding;
      videoTex.colorSpace = THREE.SRGBColorSpace ?? THREE.SRGBColorSpace; // forward compat
      videoTex.minFilter = THREE.LinearFilter;
      videoTex.magFilter = THREE.LinearFilter;
      videoTex.generateMipmaps = false;
      videoTex.needsUpdate = false; // will flip true once playing

      // set once attached
      plane.material.map = null;
      plane.material.needsUpdate = true;

      // When video metadata is known, resize plane for correct aspect
      video.addEventListener('loadedmetadata', () => {
        const vw = video.videoWidth || 16, vh = video.videoHeight || 9;
        const aspect = vw / Math.max(1, vh);
        const height = 2.8 / aspect; // keep width 2.8m
        plane.geometry.dispose();
        plane.geometry = new THREE.PlaneGeometry(2.8, height);
      });
    }

    function setupXRButton() {
      document.body.appendChild(VRButton.createButton(renderer));
      // request hand-tracking optionally (we’ll wire visuals later)
      renderer.xr.setSessionInit({
        optionalFeatures: ['local-floor', 'hand-tracking']
      });
    }

    // ====== PLAYBACK FLOW ======
    loadBtn.addEventListener('click', async () => {
      loadBtn.disabled = true;
      status('loading…');
      try {
        await attachSource(STREAM_URL);
        // user gesture already happened (click), try to play
        await video.play();
        // unmute (Oculus usually allows after gesture)
        video.muted = false;

        // bind texture
        plane.material.map = videoTex;
        plane.material.needsUpdate = true;
        videoTex.needsUpdate = true;

        status('playing');
      } catch (e) {
        status('playback blocked – tap button again if needed');
        console.error(e);
        loadBtn.disabled = false;
      }
    });

    // ====== RENDER LOOP ======
    function tick() {
      renderer.setAnimationLoop(() => {
        // keep texture fresh
        if (!video.paused && !video.ended) {
          videoTex.needsUpdate = true;
        }
        renderer.render(scene, camera);
      });
    }

    function status(msg) { statusEl.textContent = msg; }
  </script>
</body>
</html>