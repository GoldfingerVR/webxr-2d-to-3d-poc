<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"/>
<title>WebXR 2D→3D POC — MiDaS Small, VR Depth</title>
<style>
  html,body{margin:0;height:100%;background:#000;overflow:hidden;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}
  #hud{position:fixed;z-index:3;left:16px;top:16px;display:flex;gap:8px;align-items:center}
  .pill{background:#303030;color:#e0e0e0;border-radius:999px;padding:6px 10px;font-size:12px;border:1px solid #444}
  .btn{cursor:pointer;user-select:none}
  .btn[aria-disabled="true"]{opacity:.45;cursor:not-allowed}
  #status{opacity:.85}
  #panel{position:fixed;right:16px;top:16px;display:flex;align-items:center;gap:8px;z-index:3}
  #panel label{color:#ddd;font-size:13px;display:flex;align-items:center;gap:6px}
  /* Overlay no longer intercepts clicks (so Enter VR stays clickable) */
  #overlay{
    position:fixed;inset:0;display:none;flex-direction:column;gap:10px;
    align-items:center;justify-content:center;z-index:2;background:rgba(0,0,0,.45);
    pointer-events:none;
  }
  #dlbox{width:min(520px,86vw);background:#151515;border:1px solid #333;border-radius:12px;padding:16px}
  #bar{height:10px;background:#2a2a2a;border-radius:999px;overflow:hidden}
  #bar>span{display:block;height:100%;width:0%;background:#00a86b}
  #msg{color:#ccc;font-size:13px;margin-top:8px}
  #diag{position:fixed;left:12px;bottom:12px;color:#888;font-size:11px;white-space:pre-line;z-index:3;max-width:92vw}
  video{position:fixed;left:-9999px;top:-9999px;width:1px;height:1px}
  canvas{display:block}
</style>
</head>
<body>
  <!-- Left HUD -->
  <div id="hud">
    <span class="pill">Build v0.30</span>
    <span id="enterVR" class="pill btn" aria-disabled="true">Enter VR</span>
    <span id="status" class="pill">idle</span>
  </div>

  <!-- Right controls -->
  <div id="panel">
    <label class="pill"><input id="autoplayCk" type="checkbox"/> Enable Autoplay</label>
    <span class="pill">Video: sample MP4</span>
  </div>

  <!-- Non-blocking model overlay (also mirrored inside VR as 3D panel) -->
  <div id="overlay">
    <div id="dlbox">
      <div style="color:#e6e6e6;font-weight:700;margin-bottom:6px">Preparing 3D Depth (MiDaS Small)</div>
      <div id="bar"><span></span></div>
      <div id="msg">Downloading model…</div>
    </div>
  </div>

  <!-- Hidden media source and preproc canvas -->
  <video id="vid" playsinline muted crossorigin="anonymous"></video>
  <canvas id="cPre" width="256" height="256" style="position:fixed;left:-9999px;top:-9999px"></canvas>

  <div id="diag"></div>

  <script type="module">
    import * as THREE from 'https://unpkg.com/three@0.160.0/build/three.module.js';
    import 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/ort.min.js';

    // --------- CONFIG ----------
    const STREAM_URL   = 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4';
    const MODEL_URL    = 'models/midas_v21_small_256.onnx';   // your repo file
    const CACHE_NAME   = 'midas-small-v1';                    // bump to force re-download
    const PARALLAX     = 0.032;                               // meters (small = comfortable)
    const INFER_EVERY  = 2;                                   // run depth every N frames

    // ---------- DOM ----------
    const video    = document.getElementById('vid');
    const enterVR  = document.getElementById('enterVR');
    const autoplay = document.getElementById('autoplayCk');
    const overlay  = document.getElementById('overlay');
    const barInner = document.querySelector('#bar>span');
    const msg      = document.getElementById('msg');
    const statusE  = document.getElementById('status');
    const diag     = document.getElementById('diag');
    const cPre     = document.getElementById('cPre');
    const ctxPre   = cPre.getContext('2d', { willReadFrequently:true });

    // ---------- Three / XR ----------
    let renderer, scene, camera, sessionXR=null;
    let videoTex, depthTex, quadLeft, quadRight, monoMesh, shaderLeft, shaderRight;
    let readyStereo=false;

    // Depth state
    let ortSession=null, modelInputName='input';
    let frameCount=0, lastDepthImageData=null, depthW=256, depthH=256;

    // VR progress HUD
    let vrHUD = null;

    initThree();
    createMonoPlane();
    wireUI();
    animate();
    probeXR();

    function wireUI(){
      autoplay.addEventListener('change', async ()=>{
        if (autoplay.checked){
          await startPlayback();
          enterVR.setAttribute('aria-disabled', (await canXR()) ? 'false':'true');
        }else{
          video.pause();
          enterVR.setAttribute('aria-disabled', 'true');
          status('autoplay disabled');
        }
      });
      enterVR.addEventListener('click', async ()=>{
        if (enterVR.getAttribute('aria-disabled')==='true') return;
        await startXR();
      });
    }

    async function startPlayback(){
      try{
        video.src = STREAM_URL;
        await video.play();
        video.muted = false;
        bindVideoTexture();
        status('playing (mono)');
      }catch(e){
        status('autoplay blocked'); console.warn(e);
      }
    }

    function bindVideoTexture(){
      if (!videoTex){
        videoTex = new THREE.VideoTexture(video);
        videoTex.colorSpace = THREE.SRGBColorSpace;
        videoTex.minFilter = THREE.LinearFilter;
        videoTex.magFilter = THREE.LinearFilter;
        videoTex.generateMipmaps = false;
      }
      monoMesh.material.map = videoTex;
      monoMesh.material.needsUpdate = true;

      video.addEventListener('loadedmetadata', ()=>{
        const w = video.videoWidth||16, h = video.videoHeight||9;
        const aspect = w/Math.max(1,h);
        const width = 2.8, height = width/aspect;
        monoMesh.geometry.dispose();
        monoMesh.geometry = new THREE.PlaneGeometry(width,height);
      }, { once:true });
    }

    function createMonoPlane(){
      const geom = new THREE.PlaneGeometry(2.8,1.575);
      const mat  = new THREE.MeshBasicMaterial({ color:0xffffff });
      monoMesh = new THREE.Mesh(geom,mat);
      monoMesh.position.set(0,1.6,-2.0);
      scene.add(monoMesh);
    }

    function buildStereoWithShader(){
      if (!videoTex || !lastDepthImageData) return;
      monoMesh.visible=false;

      const depthData = new Uint8Array(lastDepthImageData.buffer.slice(0));
      depthTex = new THREE.DataTexture(depthData, depthW, depthH, THREE.LuminanceFormat);
      depthTex.needsUpdate=true;

      const width  = monoMesh.geometry.parameters.width;
      const height = monoMesh.geometry.parameters.height;
      const geom   = new THREE.PlaneGeometry(width,height);

      const makeMat = (eyeSign)=> new THREE.ShaderMaterial({
        uniforms:{
          uVideo:{value:videoTex},
          uDepth:{value:depthTex},
          uParallax:{value: PARALLAX*(eyeSign>0?1:-1)}
        },
        vertexShader:`varying vec2 vUv; void main(){ vUv=uv; gl_Position=projectionMatrix*modelViewMatrix*vec4(position,1.0); }`,
        fragmentShader:`
          precision highp float;
          uniform sampler2D uVideo, uDepth;
          uniform float uParallax;
          varying vec2 vUv;
          void main(){
            float d = texture2D(uDepth, vUv).r;      // 0..1
            float disp = (0.5 - d) * uParallax;       // center disparity around mid-depth
            vec2 uv = vec2(vUv.x + disp, vUv.y);
            gl_FragColor = texture2D(uVideo, uv);
          }
        `,
        depthTest:false, depthWrite:false
      });

      shaderLeft  = makeMat(-1);
      shaderRight = makeMat(+1);
      quadLeft  = new THREE.Mesh(geom.clone(), shaderLeft);
      quadRight = new THREE.Mesh(geom.clone(), shaderRight);
      quadLeft.position.copy(monoMesh.position);
      quadRight.position.copy(monoMesh.position);
      quadLeft.layers.set(1);  // left eye
      quadRight.layers.set(2); // right eye
      scene.add(quadLeft); scene.add(quadRight);
      readyStereo=true;
    }

    async function startXR(){
      try{
        sessionXR = await navigator.xr.requestSession('immersive-vr', {
          requiredFeatures:['local-floor'],
          optionalFeatures:['hand-tracking']
        });
        renderer.xr.setSession(sessionXR);
        status('VR started');

        // show overlay (non-blocking) and in-VR HUD
        showOverlay('Downloading model…');
        createVRHud(); updateVRHud(0,'Downloading model…');

        // fetch from Cache first
        const modelBytes = await getModelWithCache(MODEL_URL, (p)=>{
          setProgress(p, 'Downloading model…');
        });

        setProgress(1, 'Initializing depth engine…');
        await initOrt(modelBytes);
        setProgress(1, 'Model ready — enabling 3D');
        hideOverlay();
        destroyVRHud();

        // first inference + build stereo
        await runDepthOnce();
        buildStereoWithShader();
        status('VR 3D active');

        sessionXR.addEventListener('end', ()=>{
          status('VR ended');
          if (quadLeft) quadLeft.visible=false;
          if (quadRight) quadRight.visible=false;
          monoMesh.visible=true;
        });
      }catch(e){
        status('VR failed'); console.error(e);
        hideOverlay(); destroyVRHud();
      }
    }

    // ---- Model caching with Cache Storage API ----
    async function getModelWithCache(url, onProgress){
      try{
        const cache = await caches.open(CACHE_NAME);
        let res = await cache.match(url);
        if (res){
          // Return cached bytes (no progress possible)
          onProgress && onProgress(1);
          return await (await res.blob()).arrayBuffer();
        }
        // Fetch with progress and then cache it
        const ab = await fetchWithProgress(url, onProgress);
        await cache.put(url, new Response(ab, { headers:{ 'Content-Type':'application/octet-stream' } }));
        return ab;
      }catch(err){
        console.warn('Cache API failed, falling back to direct fetch', err);
        return await fetchWithProgress(url, onProgress);
      }
    }

    // Progress-aware fetch (handles unknown lengths)
    async function fetchWithProgress(url, onProgress){
      const res = await fetch(url);
      const len = +res.headers.get('Content-Length') || 0;
      if (!res.body || !res.ok){
        // fallback: just read all
        const ab = await res.arrayBuffer();
        onProgress && onProgress(1);
        return ab;
      }
      const reader = res.body.getReader();
      let received=0; const chunks=[];
      for(;;){
        const {done, value} = await reader.read();
        if (done) break;
        chunks.push(value); received += value.byteLength;
        if (len && onProgress) onProgress(received/len);
      }
      const blob = new Blob(chunks);
      onProgress && onProgress(1);
      return await blob.arrayBuffer();
    }

    // ---- ORT init (robust for Oculus Browser) ----
    async function initOrt(modelArrayBuffer){
      // Ensure wasm path & conservative threading for broader compatibility
      ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/';
      const opts = {
        executionProviders:['wasm'],
        graphOptimizationLevel:'all',
        intraOpNumThreads: 1
      };
      // Create session from bytes
      ortSession = await ort.InferenceSession.create(modelArrayBuffer, opts);
      // Auto-detect model input name
      const names = ortSession.inputNames;
      if (names && names.length) modelInputName = names[0];
    }

    function showOverlay(text){ overlay.style.display='flex'; if (text) msg.textContent=text; }
    function hideOverlay(){ overlay.style.display='none'; }
    function setProgress(p, text){
      barInner.style.width = (Math.max(0,Math.min(1,p))*100).toFixed(1)+'%';
      if (text) msg.textContent = text + (p>=0 && p<=1 ? ` ${ (p*100).toFixed(1)}%` : '');
      updateVRHud(p, text);
    }

    // Simple VR progress HUD (3D)
    function createVRHud(){
      if (vrHUD) return;
      const group = new THREE.Group();

      // panel
      const panel = new THREE.Mesh(
        new THREE.PlaneGeometry(0.7, 0.18),
        new THREE.MeshBasicMaterial({ color:0x111111 })
      );
      panel.position.set(0, 1.35, -1.3);
      group.add(panel);

      // bar bg
      const barBG = new THREE.Mesh(
        new THREE.PlaneGeometry(0.62, 0.02),
        new THREE.MeshBasicMaterial({ color:0x333333 })
      );
      barBG.position.set(0, 1.34, -1.29);
      group.add(barBG);

      // bar fill (scale X)
      const barFill = new THREE.Mesh(
        new THREE.PlaneGeometry(0.62, 0.02),
        new THREE.MeshBasicMaterial({ color:0x00a86b })
      );
      barFill.position.set(-0.31, 1.34, -1.28);
      barFill.scale.set(0.0001, 1, 1);
      group.add(barFill);

      // label (canvas texture)
      const labelCanvas = document.createElement('canvas');
      labelCanvas.width = 512; labelCanvas.height = 64;
      const lctx = labelCanvas.getContext('2d');
      const tex = new THREE.CanvasTexture(labelCanvas);
      tex.minFilter = THREE.LinearFilter; tex.magFilter = THREE.LinearFilter;
      const label = new THREE.Mesh(
        new THREE.PlaneGeometry(0.62, 0.06),
        new THREE.MeshBasicMaterial({ map: tex, transparent:true })
      );
      label.position.set(0, 1.39, -1.29);
      group.add(label);

      group.userData = { barFill, labelCanvas, lctx, tex };
      scene.add(group);
      vrHUD = group;
      updateVRHud(0,'Downloading model…');
    }

    function updateVRHud(p, text){
      if (!vrHUD) return;
      const { barFill, labelCanvas, lctx, tex } = vrHUD.userData;
      const clamped = Math.max(0, Math.min(1, (Number.isFinite(p)?p:0)));
      const widthFull = 0.62;
      const newWidth = Math.max(0.001, widthFull*clamped);
      barFill.scale.set(clamped, 1, 1);
      barFill.position.x = -widthFull/2 + newWidth/2;

      lctx.clearRect(0,0,labelCanvas.width,labelCanvas.height);
      lctx.fillStyle = '#cccccc';
      lctx.font = '28px system-ui, -apple-system, Segoe UI, Roboto, sans-serif';
      lctx.textAlign = 'center'; lctx.textBaseline = 'middle';
      const t = text ? `${text} ${Number.isFinite(p)?(p*100).toFixed(0)+'%':''}` : '';
      lctx.fillText(t, labelCanvas.width/2, labelCanvas.height/2);
      tex.needsUpdate = true;
    }

    function destroyVRHud(){
      if (!vrHUD) return;
      scene.remove(vrHUD);
      vrHUD.traverse(obj=>{
        if (obj.material?.map?.dispose) obj.material.map.dispose();
        if (obj.material?.dispose) obj.material.dispose();
        if (obj.geometry?.dispose) obj.geometry.dispose();
      });
      vrHUD=null;
    }

    // ---- Depth inference ----
    async function runDepthOnce(){
      if (!ortSession) return;
      ctxPre.drawImage(video, 0, 0, 256, 256);
      const img = ctxPre.getImageData(0,0,256,256);
      const src = img.data;
      const chw = new Float32Array(256*256*3);
      let p=0;
      for (let i=0;i<src.length;i+=4){
        chw[p++] = src[i]/255;     // R
        chw[p++] = src[i+1]/255;   // G
        chw[p++] = src[i+2]/255;   // B
      }
      const tensor = new ort.Tensor('float32', chw, [1,3,256,256]);

      // Auto-detected input name
      const feeds = {}; feeds[modelInputName] = tensor;
      const out = await ortSession.run(feeds);
      const outName = Object.keys(out)[0];
      const depth = out[outName].data;

      // Normalize → 8-bit grayscale
      let mn=Infinity, mx=-Infinity;
      for (let i=0;i<depth.length;i++){ const v=depth[i]; if (v<mn) mn=v; if (v>mx) mx=v; }
      const range = Math.max(1e-6, mx-mn);
      const N = depth.length;
      const gray = new Uint8ClampedArray(N);
      for (let i=0;i<N;i++){ gray[i] = Math.round(((depth[i]-mn)/range)*255); }
      lastDepthImageData = gray; depthW=256; depthH=256;
      if (depthTex){ depthTex.image.data = new Uint8Array(gray.buffer.slice(0)); depthTex.needsUpdate=true; }
    }

    // ---------- Three boilerplate ----------
    function initThree(){
      renderer = new THREE.WebGLRenderer({ antialias:true, alpha:false });
      renderer.setPixelRatio(Math.min(2, window.devicePixelRatio));
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.xr.enabled = true;
      document.body.appendChild(renderer.domElement);

      scene = new THREE.Scene();
      scene.background = new THREE.Color(0x000000);

      camera = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.01, 100);
      camera.position.set(0, 1.6, 0);

      scene.add(new THREE.AmbientLight(0xffffff, 0.7));

      const floor = new THREE.Mesh(
        new THREE.CircleGeometry(3.5, 64),
        new THREE.MeshBasicMaterial({ color:0x101010 })
      );
      floor.rotation.x = -Math.PI/2;
      floor.position.y = 0;
      scene.add(floor);

      window.addEventListener('resize', ()=>{
        camera.aspect = window.innerWidth/window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    }

    async function canXR(){
      if (!('xr' in navigator)) return false;
      try{ return await navigator.xr.isSessionSupported('immersive-vr'); }
      catch{ return false; }
    }
    async function probeXR(){
      const httpsOK = (location.protocol==='https:')||(location.hostname==='localhost');
      const supported = httpsOK && await canXR();
      enterVR.setAttribute('aria-disabled', supported?'false':'true');
      diag.textContent =
        `https/localhost: ${httpsOK}\n`+
        `navigator.xr: ${!!navigator.xr}\n`+
        `immersive-vr supported: ${supported}`;
    }

    function status(m){ statusE.textContent = m; }

    function animate(){
      renderer.setAnimationLoop(async ()=>{
        if (videoTex && !video.paused && !video.ended) videoTex.needsUpdate = true;
        if (sessionXR && ortSession && (frameCount++ % INFER_EVERY === 0)){
          try{ await runDepthOnce(); }catch(e){ /* keep going */ }
        }
        renderer.render(scene, camera);
      });
    }
  </script>
</body>
</html>