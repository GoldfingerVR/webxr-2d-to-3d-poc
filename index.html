<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"/>
  <title>WebXR 2D→3D POC — v0.20 (Depth On-Device)</title>
  <style>
    html,body{margin:0;height:100%;background:#000;overflow:hidden;font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif}
    video{position:fixed;left:-9999px;top:-9999px;width:1px;height:1px}
    canvas{display:block}
    /* HUD (top-left) */
    #hud{position:fixed;z-index:10;left:16px;top:16px;display:flex;gap:8px;align-items:center}
    .pill{background:#303030;color:#e0e0e0;border-radius:999px;padding:6px 10px;font-size:12px;border:1px solid #444;user-select:none}
    .btn-pill{cursor:pointer}
    .btn-pill[aria-disabled="true"]{opacity:.45;cursor:not-allowed}
    /* Bottom status strip */
    #statusBar{position:fixed;left:50%;bottom:16px;transform:translateX(-50%);display:flex;gap:8px;align-items:center;z-index:11}
    .status-chip{background:#141414;border:1px solid #333;color:#ddd;padding:8px 12px;border-radius:10px;font-size:12px;white-space:nowrap}
    .ok{color:#86f7b1}.warn{color:#ffd36e}.bad{color:#ff7a7a}
    /* Loader */
    #loader{position:fixed;right:16px;bottom:16px;background:#111;border:1px solid #333;color:#ddd;border-radius:12px;padding:10px 12px;z-index:11;min-width:260px;display:none}
    #bar{height:6px;background:#222;border-radius:999px;overflow:hidden;margin-top:8px}
    #fill{height:100%;width:0%;background:#00a86b}
    /* Start overlay */
    #center{position:fixed;inset:0;display:flex;flex-direction:column;gap:14px;align-items:center;justify-content:center;z-index:12;background:rgba(0,0,0,.55)}
    .cta{background:#00a86b;border:none;color:#fff;font-weight:700;font-size:18px;padding:14px 22px;border-radius:12px;cursor:pointer;box-shadow:0 6px 18px rgba(0,0,0,.35)}
    .cta[disabled]{opacity:.45;cursor:not-allowed}
    .sub{color:#bbb;font-size:13px;text-align:center}
    /* Log */
    #diag{position:fixed;left:12px;bottom:12px;color:#aaa;font-size:12px;white-space:pre-line;z-index:9;max-width:92vw}
  </style>
  <!-- ONNX Runtime (WASM) -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.2/dist/ort-web.min.js"></script>
</head>
<body>
  <!-- HUD -->
  <div id="hud">
    <span class="pill">Build v0.20</span>
    <span id="enterVR" class="pill btn-pill" aria-disabled="true">Enter VR</span>
    <span id="playToggle" class="pill btn-pill" aria-disabled="true">Play</span>
    <span id="status" class="pill">idle</span>
  </div>

  <!-- Status chips -->
  <div id="statusBar">
    <span class="status-chip">3D Engine: <strong id="engineState" class="warn">waiting</strong></span>
    <span class="status-chip">Mode: <strong id="stereoMode">2D (mono)</strong></span>
  </div>

  <!-- Loader -->
  <div id="loader">
    <div id="loaderText">Preparing depth model…</div>
    <div id="bar"><div id="fill"></div></div>
  </div>

  <!-- Start -->
  <div id="center">
    <button id="startBtn" class="cta">Start Session</button>
    <div class="sub">Downloads the depth model, warms up the engine, then enables Play + Enter VR.</div>
  </div>

  <!-- Hidden media -->
  <video id="vid" playsinline muted crossorigin="anonymous"></video>
  <div id="diag"></div>

  <script type="module">
    import * as THREE from 'https://unpkg.com/three@0.160.0/build/three.module.js';

    // -------------------- Config --------------------
    const STREAM_URL  = 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/Sintel.mp4';
    const MODEL_URL   = './models/midas_v21_small_256.onnx'; // must exist on your Pages
    const DEPTH_SIZE  = 256;          // MiDaS small expects 256
    const DEPTH_FPS   = 12;           // run depth ~12fps to keep perf stable
    const DEPTH_DISPARITY = 0.12;     // **big** disparity so 3D is obvious (tune down later)
    const PARALLAX_FALLBACK = 0.06;   // fallback shift if depth fails

    // -------------------- DOM --------------------
    const video      = document.getElementById('vid');
    const enterVR    = document.getElementById('enterVR');
    const playToggle = document.getElementById('playToggle');
    const statusE    = document.getElementById('status');
    const engineState= document.getElementById('engineState');
    const stereoMode = document.getElementById('stereoMode');
    const loader     = document.getElementById('loader');
    const loaderText = document.getElementById('loaderText');
    const fill       = document.getElementById('fill');
    const center     = document.getElementById('center');
    const startBtn   = document.getElementById('startBtn');
    const diag       = document.getElementById('diag');

    // -------------------- State --------------------
    let renderer, scene, camera;
    let videoTex, monoPlane;
    let stereo = { left:null, right:null };
    let xrSession = null;

    const engine = {
      downloading:false,
      ready:false,      // model downloaded
      warm:false,       // session created
      active:false,     // rendering stereo in VR
      mode:'mono',      // 'mono' | 'depth' | 'parallax'
      ortSession:null,
      inputName:null,
      outputName:null,
      lastDepthTime:0
    };

    // CPU helpers for depth preprocessing
    const workCanvas = document.createElement('canvas');
    const workCtx    = workCanvas.getContext('2d', { willReadFrequently:true });
    workCanvas.width = DEPTH_SIZE; workCanvas.height = DEPTH_SIZE;

    // For passing depth to shader
    let depthTex = null; // THREE.DataTexture (R channel)

    // -------------------- Init --------------------
    initThree();
    createMonoPlane();
    wireUI();
    animate();
    probeXR();

    function wireUI(){
      startBtn.addEventListener('click', async ()=>{
        startBtn.disabled = true;
        await startSessionFlow().catch(()=>{});
        if (engine.ready && engine.warm) center.style.display = 'none';
        startBtn.disabled = false;
      });

      playToggle.addEventListener('click', async ()=>{
        if (playToggle.getAttribute('aria-disabled')==='true') return;
        try{
          if (!video.src) video.src = STREAM_URL;
          if (video.paused) {
            await video.play();
            video.muted = false;
            playToggle.textContent = 'Pause';
            bindVideoTexture();
          } else {
            video.pause();
            playToggle.textContent = 'Play';
          }
        }catch(e){ log('play/pause error: '+(e?.message||e)); }
      });

      enterVR.addEventListener('click', async ()=>{
        if (enterVR.getAttribute('aria-disabled')==='true') return;
        await startXR();
      });

      video.addEventListener('loadedmetadata', ()=>{
        const w = video.videoWidth || 16, h = video.videoHeight || 9;
        const aspect = w / Math.max(1, h);
        const width = 2.8, height = width / aspect;
        monoPlane.geometry.dispose();
        monoPlane.geometry = new THREE.PlaneGeometry(width, height);
        if (stereo.left && stereo.right) {
          [stereo.left, stereo.right].forEach(mesh=>{
            mesh.geometry.dispose();
            mesh.geometry = new THREE.PlaneGeometry(width, height);
          });
        }
      }, { once:true });
    }

    // -------------------- Start flow --------------------
    async function startSessionFlow(){
      status('starting…');
      engineState.textContent = 'initializing…'; engineState.className='warn';
      showLoader(true);

      // 1) Download model with progress
      try{
        engine.downloading = true; engine.ready=false; engine.warm=false;
        const buf = await fetchWithProgress(MODEL_URL, r=>updateProgress(r));
        engine.downloading=false; engine.ready=true;
        updateProgress(1);
        loaderText.textContent='Model downloaded';
        engineState.textContent='downloaded'; engineState.className='ok';

        // 2) Warm ORT session
        loaderText.textContent='Warming depth engine…';
        const session = await ort.InferenceSession.create(buf, { executionProviders:['wasm'] });
        engine.ortSession = session;

        // Choose first input/output names safely
        const ins = session.inputNames?.length ? session.inputNames : Object.keys(session.inputMetadata||{});
        engine.inputName = ins[0];
        const outs = session.outputNames?.length ? session.outputNames : Object.keys(session.outputMetadata||{});
        engine.outputName = outs[0];

        // Dummy warmup
        const dummy = new Float32Array(1*3*DEPTH_SIZE*DEPTH_SIZE);
        const t = new ort.Tensor('float32', dummy, [1,3,DEPTH_SIZE,DEPTH_SIZE]);
        const feeds={}; feeds[engine.inputName]=t;
        await session.run(feeds).catch(()=>{});
        engine.warm = true;

        // 3) Enable controls
        playToggle.setAttribute('aria-disabled','false');
        enterVR.setAttribute('aria-disabled','false');
        loaderText.textContent='Depth ready';
        setTimeout(()=>showLoader(false), 700);
        engineStatus();
        status('ready');
      }catch(e){
        // Model failed → keep stereo via parallax fallback
        engine.downloading=false; engine.ready=false; engine.warm=false;
        loaderText.textContent='Model failed (fallback stereo available)';
        engineState.textContent='failed'; engineState.className='bad';
        playToggle.setAttribute('aria-disabled','false');
        enterVR.setAttribute('aria-disabled','false');
        engineStatus();
        status('model failed');
        log('Model error: '+(e?.message||e));
      }
    }

    // -------------------- Depth pipeline --------------------
    function preprocessToMidasRGB(img){
      // Draw to 256x256, get ImageData, convert to float32 NCHW RGB normalized (0..1)
      workCtx.drawImage(img, 0, 0, DEPTH_SIZE, DEPTH_SIZE);
      const d = workCtx.getImageData(0,0,DEPTH_SIZE,DEPTH_SIZE).data;
      const out = new Float32Array(1*3*DEPTH_SIZE*DEPTH_SIZE);
      let i=0, rOff=0, gOff=DEPTH_SIZE*DEPTH_SIZE, bOff=2*DEPTH_SIZE*DEPTH_SIZE;
      for (let y=0; y<DEPTH_SIZE; y++){
        for (let x=0; x<DEPTH_SIZE; x++, i+=4){
          const r=d[i]/255, g=d[i+1]/255, b=d[i+2]/255;
          const idx = y*DEPTH_SIZE + x;
          out[rOff+idx]=r; out[gOff+idx]=g; out[bOff+idx]=b;
        }
      }
      return out;
    }

    async function computeDepthIfDue(nowMs){
      if (!engine.ortSession || video.paused || video.ended) return;
      if (nowMs - engine.lastDepthTime < (1000/DEPTH_FPS)) return;
      engine.lastDepthTime = nowMs;

      try{
        const tensorData = preprocessToMidasRGB(video);
        const input = new ort.Tensor('float32', tensorData, [1,3,DEPTH_SIZE,DEPTH_SIZE]);
        const feeds = {}; feeds[engine.inputName]=input;
        const out = await engine.ortSession.run(feeds);
        const first = engine.outputName ? out[engine.outputName] : Object.values(out)[0];
        // Normalize depth to 0..1 (MiDaS is inverse depth-ish; we scale robustly)
        const arr = first.data;
        let min=Infinity, max=-Infinity;
        for (let i=0;i<arr.length;i++){ const v=arr[i]; if (v<min) min=v; if (v>max) max=v; }
        const range = Math.max(1e-6, max-min);
        const norm = new Uint8Array(arr.length);
        for (let i=0;i<arr.length;i++){
          const d = (arr[i]-min)/range; // 0..1
          norm[i] = Math.max(0, Math.min(255, Math.round(d*255)));
        }
        updateDepthTexture(norm);
        if (engine.mode!=='depth') { engine.mode='depth'; engineStatus(); }
      }catch(e){
        if (engine.mode!=='parallax'){ engine.mode='parallax'; engineStatus(); }
      }
    }

    function updateDepthTexture(u8){
      if (!depthTex){
        depthTex = new THREE.DataTexture(u8, DEPTH_SIZE, DEPTH_SIZE, THREE.RedFormat);
        depthTex.colorSpace = THREE.NoColorSpace;
        depthTex.needsUpdate = true;
      } else {
        depthTex.image.data.set(u8);
        depthTex.needsUpdate = true;
      }
    }

    // -------------------- Three / materials --------------------
    let matLeft = null, matRight = null;

    const depthShader = {
      uniforms: {
        map: { value: null },          // video
        depthMap: { value: null },     // depth (R8)
        disparity: { value: DEPTH_DISPARITY }, // strong for now
        eyeSign: { value: -1.0 },      // -1 left, +1 right
        videoAspect: { value: 16/9 },
        depthAspect: { value: 1.0 }
      },
      vertexShader: `
        varying vec2 vUv;
        void main(){
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position,1.0);
        }
      `,
      fragmentShader: `
        precision mediump float;
        uniform sampler2D map;
        uniform sampler2D depthMap;
        uniform float disparity;
        uniform float eyeSign;
        uniform float videoAspect;
        uniform float depthAspect;
        varying vec2 vUv;

        // Remap vUv from video aspect to square depth map, sample depth, then offset UV in X
        vec2 toDepthUV(vec2 uv){
          // letterbox video to square
          float va = videoAspect;
          vec2 centered = uv;
          if (va > 1.0){
            // video wider than tall → vertical bars in depth space
            float pad = (1.0 - 1.0/va)*0.5;
            centered.x = pad + uv.x*(1.0-2.0*pad);
          }else{
            // video taller → horizontal bars
            float pad = (1.0 - va)*0.5;
            centered.y = pad + uv.y*(1.0-2.0*pad);
          }
          return centered;
        }

        void main(){
          vec2 dUV = toDepthUV(vUv);
          float d = texture2D(depthMap, dUV).r;     // 0..1
          // Front objects (bigger d) shift more; push opposite per eye
          float shift = (d - 0.5) * disparity * eyeSign;
          vec2 videoUV = vUv + vec2(shift, 0.0);

          // Clamp to avoid black seams
          videoUV = clamp(videoUV, vec2(0.001,0.001), vec2(0.999,0.999));

          gl_FragColor = texture2D(map, videoUV);
        }
      `
    };

    function makeDepthMat(eyeSign){
      const m = new THREE.ShaderMaterial({
        uniforms: THREE.UniformsUtils.clone(depthShader.uniforms),
        vertexShader: depthShader.vertexShader,
        fragmentShader: depthShader.fragmentShader
      });
      m.uniforms.eyeSign.value = eyeSign;
      m.uniforms.map.value = videoTex;
      m.uniforms.depthMap.value = depthTex;
      // Update aspects
      const va = (video.videoWidth||16) / Math.max(1, (video.videoHeight||9));
      m.uniforms.videoAspect.value = va;
      return m;
    }

    function bindVideoTexture(){
      if (!videoTex) {
        videoTex = new THREE.VideoTexture(video);
        videoTex.colorSpace = THREE.SRGBColorSpace;
        videoTex.minFilter = THREE.LinearFilter;
        videoTex.magFilter = THREE.LinearFilter;
        videoTex.generateMipmaps = false;
      }
      monoPlane.material.map = videoTex;
      monoPlane.material.needsUpdate = true;
    }

    function createMonoPlane(){
      const geom = new THREE.PlaneGeometry(2.8, 1.575);
      const mat  = new THREE.MeshBasicMaterial({ color:0xffffff });
      monoPlane = new THREE.Mesh(geom, mat);
      monoPlane.position.set(0, 1.6, -2.0);
      scene.add(monoPlane);
    }

    function buildStereoPlanes(){
      if (!videoTex) return;
      monoPlane.visible = false;

      const baseGeom = monoPlane.geometry.clone();

      // If we have depth texture + session, build shader materials, else fallback
      if (engine.mode === 'depth' && depthTex){
        matLeft  = makeDepthMat(-1.0);
        matRight = makeDepthMat(+1.0);
      } else {
        matLeft  = new THREE.MeshBasicMaterial({ map: videoTex });
        matRight = new THREE.MeshBasicMaterial({ map: videoTex });
      }

      stereo.left  = new THREE.Mesh(baseGeom.clone(), matLeft);
      stereo.right = new THREE.Mesh(baseGeom.clone(), matRight);

      stereo.left.position.copy(monoPlane.position);
      stereo.right.position.copy(monoPlane.position);

      stereo.left.layers.set(1);
      stereo.right.layers.set(2);

      const s = 1.01; stereo.left.scale.set(s,s,1); stereo.right.scale.set(s,s,1);
      scene.add(stereo.left); scene.add(stereo.right);

      // If no depth, apply visible fallback shift; with depth, planes overlap (no offset here).
      if (engine.mode === 'depth'){
        stereo.left.position.x  = monoPlane.position.x;
        stereo.right.position.x = monoPlane.position.x;
      } else {
        stereo.left.position.x  = monoPlane.position.x - (PARALLAX_FALLBACK/2);
        stereo.right.position.x = monoPlane.position.x + (PARALLAX_FALLBACK/2);
      }

      engine.active = true;
      engineStatus();
    }

    // -------------------- Loader/Status --------------------
    function showLoader(show){ loader.style.display = show ? 'block' : 'none'; }
    function updateProgress(ratio){
      const pct = Math.max(0, Math.min(100, Math.floor(ratio*100)));
      fill.style.width = pct + '%';
      loaderText.textContent = (pct<100) ? `Downloading model… ${pct}%` : 'Model downloaded';
    }
    async function fetchWithProgress(url, onProgress){
      const res = await fetch(url, { cache:'force-cache' });
      if (!res.ok) throw new Error('HTTP '+res.status);
      const total = Number(res.headers.get('Content-Length')) || 0;
      const reader = res.body.getReader();
      let received = 0; const chunks=[];
      while(true){ const {done,value}=await reader.read(); if(done)break; chunks.push(value); received+=value.byteLength; if(total) onProgress(received/total); }
      const blob = new Blob(chunks); return await blob.arrayBuffer();
    }
    function engineStatus(){
      // Engine chip
      if (engine.downloading && !engine.ready){ engineState.textContent='downloading…'; engineState.className='warn'; }
      else if (engine.ready && !engine.warm){ engineState.textContent='downloaded (warming…)'; engineState.className='warn'; }
      else if (engine.ready && engine.warm && !engine.active){ engineState.textContent='ready (awaiting VR)'; engineState.className='ok'; }
      else if (engine.active){ engineState.textContent='active'; engineState.className='ok'; }
      else { engineState.textContent='waiting'; engineState.className='warn'; }

      // Mode chip
      let modeText = '2D (mono)';
      if (engine.active){
        if (engine.mode==='depth') modeText = '3D (depth)';
        else if (engine.mode==='parallax') modeText = '3D (parallax fallback)';
      } else if (engine.mode==='depth'){ modeText='2D (depth ready)'; }
      stereoMode.textContent = modeText;
    }
    function status(msg){ statusE.textContent = msg; }
    function log(msg){ diag.textContent += (diag.textContent ? '\n' : '') + msg; }

    // -------------------- WebXR --------------------
    async function startXR(){
      if (!navigator.xr) { status('WebXR not available'); log('navigator.xr missing'); return; }
      try{
        xrSession = await navigator.xr.requestSession('immersive-vr', {
          requiredFeatures: ['local-floor'],
          optionalFeatures: ['hand-tracking']
        });
        renderer.xr.setSession(xrSession);
        status('VR started');

        if (!video.src) video.src = STREAM_URL;
        if (video.paused) {
          try { await video.play(); video.muted=false; playToggle.textContent='Pause'; }
          catch(e){ log('autoplay in VR failed: '+(e?.message||e)); }
        }
        bindVideoTexture();

        // Build stereo using depth if available, else parallax
        buildStereoPlanes();

        xrSession.addEventListener('end', ()=>{
          xrSession = null;
          engine.active = false;
          monoPlane.visible = true;
          if (stereo.left) stereo.left.visible = false;
          if (stereo.right) stereo.right.visible = false;
          status('VR ended');
          engineStatus();
        });
      }catch(e){
        status('VR failed'); log('requestSession error: ' + (e?.message||e));
      }
    }
    async function probeXR(){
      const xrOK = !!navigator.xr;
      let supported = false;
      try { supported = xrOK ? await navigator.xr.isSessionSupported('immersive-vr') : false; }
      catch(e) {}
      // Enabled after model flow; Start Session turns these on
      enterVR.setAttribute('aria-disabled', (!supported) ? 'true':'false');
    }

    // -------------------- Three boilerplate --------------------
    function initThree(){
      renderer = new THREE.WebGLRenderer({ antialias:true, alpha:false });
      renderer.setPixelRatio(Math.min(2, window.devicePixelRatio));
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.xr.enabled = true;
      document.body.appendChild(renderer.domElement);

      scene = new THREE.Scene();
      scene.background = new THREE.Color(0x000000);

      camera = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.01, 100);
      camera.position.set(0, 1.6, 0);

      scene.add(new THREE.AmbientLight(0xffffff, 0.7));

      const floor = new THREE.Mesh(
        new THREE.CircleGeometry(3.5, 64),
        new THREE.MeshBasicMaterial({ color:0x101010 })
      );
      floor.rotation.x = -Math.PI/2; floor.position.y = 0; scene.add(floor);

      window.addEventListener('resize', ()=>{
        camera.aspect = window.innerWidth/window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    }

    function animate(){
      renderer.setAnimationLoop((t)=>{
        // Update video texture
        if (videoTex && !video.paused && !video.ended) videoTex.needsUpdate = true;

        // Depth updates (even outside VR, so we’re ready on entry)
        computeDepthIfDue(performance.now());

        // Keep shader uniforms fresh
        if (matLeft && matRight){
          const va = (video.videoWidth||16)/Math.max(1,(video.videoHeight||9));
          if (matLeft.uniforms.videoAspect)  matLeft.uniforms.videoAspect.value = va;
          if (matRight.uniforms.videoAspect) matRight.uniforms.videoAspect.value = va;
          if (depthTex){
            if (matLeft.uniforms.depthMap)  matLeft.uniforms.depthMap.value = depthTex;
            if (matRight.uniforms.depthMap) matRight.uniforms.depthMap.value = depthTex;
          }
          if (engine.mode==='depth'){
            if (matLeft.uniforms.disparity)  matLeft.uniforms.disparity.value  = DEPTH_DISPARITY;
            if (matRight.uniforms.disparity) matRight.uniforms.disparity.value = DEPTH_DISPARITY;
          }
        }

        renderer.render(scene, camera);
      });
    }
  </script>
</body>
</html>